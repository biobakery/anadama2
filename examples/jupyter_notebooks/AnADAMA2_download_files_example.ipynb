{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnADAMA2 Example: A workflow to download files in parallel\n",
    "\n",
    "[AnADAMA2](http://huttenhower.sph.harvard.edu/anadama2) is the next generation of AnADAMA (Another Automated Data Analysis Management Application). AnADAMA is a tool to create reproducible workflows and execute them efficiently. Tasks can be run locally or in a grid computing environment to increase efficiency. Essential information from all tasks is recorded, using the default logger and command line reporters, to ensure reproducibility. A auto-doc feature allows for workflows to generate documentation automatically to further ensure reproducibility by capturing the latest essential workflow information. AnADAMA2 was architected to be modular allowing users to customize the application by subclassing the base grid meta-schedulers, reporters, and tracked objects (ie files, executables, etc).\n",
    "\n",
    "* For additional information, see the [AnADAMA2 User Manual](https://bitbucket.org/biobakery/anadama2) or the [AnADAMA2 Tutorial](https://bitbucket.org/biobakery/biobakery/wiki/anadama2).\n",
    "* For more example workflows, download the AnADAMA2 software source and demos ( [anadama2.tar.gz](https://pypi.python.org/pypi/anadama2) ).\n",
    "* Please direct questions to the [AnADAMA Google Group](https://groups.google.com/forum/#!forum/anadama-users).\n",
    "                                                        \n",
    "**This example shows how to write a simple AnADAMA2 workflow to download three files.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the workflow from anadama2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from anadama2 import Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create a workflow instance. \n",
    "Since we are using Jupyter we need to turn off the command line interface for the workflow. \n",
    "The command line interface is helpful when executing a workflow directly from the command line. \n",
    "It allows the user to provide options like input/output folders at run-time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workflow = Workflow(cli=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Add tasks to the workflow. In this example a task will be added for each file that needs to be downloaded. \n",
    "Also we track the executable used to download the files. This will cause the tasks to rerun if the version of the\n",
    "executable is changed. It will also log the version of the executable when the tasks are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the TrackedExecutable class\n",
    "from anadama2.tracked import TrackedExecutable\n",
    "\n",
    "# set the list of urls to download\n",
    "downloads=[\"ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011175.fsa.gz\",\n",
    "    \"ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011273.fsa.gz\",\n",
    "    \"ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011180.fsa.gz\"]\n",
    "\n",
    "# add a task to the workflow to download each url\n",
    "for link in downloads:\n",
    "    workflow.add_task(\n",
    "        \"wget -O [targets[0]] [args[0]]\",\n",
    "        depends=TrackedExecutable(\"wget\"),\n",
    "        targets=link.split(\"/\")[-1],\n",
    "        args=link) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Now lets change the current working directory to see if we have any of the files already downloaded.\n",
    "We don't expect to see any of the files downloaded yet as the tasks have just been added to the workflow. \n",
    "The tasks have not yet been run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'AnADAMA2_download_files_example.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the current working directory to see we do not have any of the files downloaded yet\n",
    "import os\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Run the workflow. By executing ``go`` we run the tasks in the workflow. We can choose to do a dry run\n",
    "which will only show the tasks that would be run instead of actually running the tasks by setting ``dry_run=True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Task0\n",
      "  Dependencies (1)\n",
      "  - /usr/bin/wget (Executable)\n",
      "  Targets (1)\n",
      "  - /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011175.fsa.gz (Big File)\n",
      "  Actions (1)\n",
      "  - wget -O /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011175.fsa.gz ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011175.fsa.gz (command)\n",
      "------------------\n",
      "2 - Task2\n",
      "  Dependencies (1)\n",
      "  - /usr/bin/wget (Executable)\n",
      "  Targets (1)\n",
      "  - /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011273.fsa.gz (Big File)\n",
      "  Actions (1)\n",
      "  - wget -O /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011273.fsa.gz ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011273.fsa.gz (command)\n",
      "------------------\n",
      "3 - Task3\n",
      "  Dependencies (1)\n",
      "  - /usr/bin/wget (Executable)\n",
      "  Targets (1)\n",
      "  - /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011180.fsa.gz (Big File)\n",
      "  Actions (1)\n",
      "  - wget -O /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011180.fsa.gz ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011180.fsa.gz (command)\n",
      "------------------\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "workflow.go(dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Run the workflow again not in dry run mode to run the tasks to download the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jun 06 11:50:19) [0/3 -   0.00%] **Ready    ** Task 2: wget\n",
      "(Jun 06 11:50:19) [0/3 -   0.00%] **Started  ** Task 2: wget\n",
      "(Jun 06 11:50:21) [1/3 -  33.33%] **Completed** Task 2: wget\n",
      "(Jun 06 11:50:21) [1/3 -  33.33%] **Ready    ** Task 3: wget\n",
      "(Jun 06 11:50:21) [1/3 -  33.33%] **Started  ** Task 3: wget\n",
      "(Jun 06 11:50:24) [2/3 -  66.67%] **Completed** Task 3: wget\n",
      "(Jun 06 11:50:24) [2/3 -  66.67%] **Ready    ** Task 0: wget\n",
      "(Jun 06 11:50:24) [2/3 -  66.67%] **Started  ** Task 0: wget\n",
      "(Jun 06 11:50:27) [3/3 - 100.00%] **Completed** Task 0: wget\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "workflow.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Check the current working directory to see the files have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SRS011180.fsa.gz',\n",
       " '.ipynb_checkpoints',\n",
       " 'anadama.log',\n",
       " 'SRS011273.fsa.gz',\n",
       " 'SRS011175.fsa.gz',\n",
       " 'AnADAMA2_download_files_example.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Run the workflow again to see all tasks are skipped because the files are already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jun 06 11:50:35) [1/3 -  33.33%] **Skipped  ** Task 0: wget\n",
      "(Jun 06 11:50:35) [2/3 -  66.67%] **Skipped  ** Task 3: wget\n",
      "(Jun 06 11:50:35) [3/3 - 100.00%] **Skipped  ** Task 2: wget\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "workflow.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Delete one of the downloads and run in dry run mode to see that only the file that was deleted\n",
    "will be downloaded if the workflow is run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jun 06 11:50:46) [1/3 -  33.33%] **Skipped  ** Task 0: wget\n",
      "(Jun 06 11:50:46) [2/3 -  66.67%] **Skipped  ** Task 2: wget\n",
      "3 - Task3\n",
      "  Dependencies (1)\n",
      "  - /usr/bin/wget (Executable)\n",
      "  Targets (1)\n",
      "  - /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011180.fsa.gz (Big File)\n",
      "  Actions (1)\n",
      "  - wget -O /work/code/anadama/anadama2/jupyter_notebooks/download_files_example/SRS011180.fsa.gz ftp://public-ftp.hmpdacc.org/HM16STR/by_sample/SRS011180.fsa.gz (command)\n",
      "------------------\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "# delete one of the files\n",
    "os.remove(\"SRS011180.fsa.gz\")\n",
    "# then execute a dry run to see what will be run\n",
    "workflow.go(dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9:** Run the workflow to download the single file that we just deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jun 06 11:50:53) [1/3 -  33.33%] **Skipped  ** Task 0: wget\n",
      "(Jun 06 11:50:53) [2/3 -  66.67%] **Skipped  ** Task 2: wget\n",
      "(Jun 06 11:50:53) [2/3 -  66.67%] **Ready    ** Task 3: wget\n",
      "(Jun 06 11:50:53) [2/3 -  66.67%] **Started  ** Task 3: wget\n",
      "(Jun 06 11:50:55) [3/3 - 100.00%] **Completed** Task 3: wget\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "workflow.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10:** Import the AnADAMA2 reporter that logs information when workflows run and print the commands that were\n",
    "run for this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wget -O SRS011273.fsa.gz SRS011273.fsa.gz',\n",
       " 'wget -O SRS011180.fsa.gz SRS011180.fsa.gz',\n",
       " 'wget -O SRS011175.fsa.gz SRS011175.fsa.gz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the commands run in the workflow from the log\n",
    "from anadama2.reporters import LoggerReporter\n",
    "LoggerReporter.read_log(\"anadama.log\",\"commands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11:** Print the versions for the tracked executables for this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GNU Wget 1.18 built on linux-gnu.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoggerReporter.read_log(\"anadama.log\",\"versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 12:** Now rerun the full workflow with three tasks at once, not skipping any tasks even though the files already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Started  ** Task 2: wget\n",
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Started  ** Task 3: wget\n",
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Started  ** Task 0: wget\n",
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Ready    ** Task 2: wget\n",
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Ready    ** Task 3: wget\n",
      "(Jun 06 11:51:16) [0/3 -   0.00%] **Ready    ** Task 0: wget\n",
      "(Jun 06 11:51:18) [1/3 -  33.33%] **Completed** Task 3: wget\n",
      "(Jun 06 11:51:19) [2/3 -  66.67%] **Completed** Task 2: wget\n",
      "(Jun 06 11:51:19) [3/3 - 100.00%] **Completed** Task 0: wget\n",
      "Run Finished\n"
     ]
    }
   ],
   "source": [
    "# rerunning all commands in the workflow this time executing all three downloads at once\n",
    "workflow.go(jobs=3, skip_nothing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

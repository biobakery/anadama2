"""
Default pipeline skeleton dodo file as generated by anadama
"""

import os
import re
from os.path import basename

import yaml
from {pipeline_class.__module__} import {pipeline_class.__name__} as ThePipeline
{append_imports}

KNOWN_INPUT_DIRECTORIES = {known_input_directories}
KNOWN_INPUT_DIRECTORIES = filter(os.path.exists, KNOWN_INPUT_DIRECTORIES)
OPTIONS_DIRECTORY = {options_dir}
SKIPTASKS_FILE = "_skip.txt"

IGNORE = [ r'^\.', r'^_', r'~$', r'^#']

def ignored(fname):
    return not any( re.compile(r).search(fname) for r in IGNORE )


def split(s, n=1):
    regex = re.compile(r':\s*')
    return re.split(regex, s, n)


def _pipeline_args():
    for input_dir in KNOWN_INPUT_DIRECTORIES:
        inputs = [ os.path.join(input_dir, f)
                   for f in filter(ignored, os.listdir(input_dir)) ]
        yield basename(input_dir), inputs


def _pipeline_opts():
    option_files = filter(ignored, os.listdir(OPTIONS_DIRECTORY))
    for fname in option_files:
        with open(os.path.join(OPTIONS_DIRECTORY, fname)) as opt_f:
            name = os.path.splitext(fname)[0]
            yield name, yaml.safe_load(opt_f) or dict()


def _pipeline_skiptasks():
    while os.path.exists(SKIPTASKS_FILE):
        with open(SKIPTASKS_FILE) as skip_f:
            for key, regex in map(split, skip_f):
                regex = regex.strip()
                func = lambda task_dict: re.search(regex, task_dict[key])
                yield func
        break

    
def task_main():
    pipeline_args_dict = dict(_pipeline_args())
    pipeline_args_dict['workflow_options'] = dict(_pipeline_opts())
    pipeline_args_dict['skipfilters'] = list(_pipeline_skiptasks())
    pipeline = ThePipeline(**pipeline_args_dict)
    {append_statements}
    pipeline.configure()
    for task in pipeline:
        yield task


DOIT_CONFIG = dict(
    default_tasks = ['main'],
    pipeline_name = "{pipeline_class.name}"
)
DOIT_CONFIG['continue'] = True
